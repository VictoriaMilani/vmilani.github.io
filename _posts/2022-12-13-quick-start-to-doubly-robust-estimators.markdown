---
layout: single
title:  "Quick Start to Doubly Robust Estimators"
classes: wide
date:   2022-11-03 10:31:27 -0400
categories: R
---

In our first introduction to Causal Inference, we learn about linear estimators and propensity score weighting methods to estimate the average treatment effect conditional on covariates.

However, covariates are the main cause of counfoundness in causal inference settings, so we should ask: which method should I use? Which one is the best method? Well, actually, you can use both to guarantee unbiased estimators!

Let us imagine we are investigating the causal relationship between income and a government training program that individuals may or may not participate.

First, we create a _very simple_ static "labor market". Assume 10k workers, which we observe two variables, X1 and X2.

```r
library(tidyverse)
library(fixest)

set.seed(123)

n <- 10000

# Generate covariates
X1 <- rnorm(n)
X2 <- rnorm(n)
```

For the sake of simplicity, X1 and X2 are standard normal distributions. We can assume there is a function that simply maps these draws to real-world data variables, in this case, education and work experience.   

Let us create now a treatment variable. In several cases dealing with real world data, where there is no randomized experiment, assignment to treatment is actually _correlated_ somehow to certain variables in a functional form we may not know.

In this labor market example, individuals may observe the opportunity enter the program but some of them are inclined to not participate given they accumulated enough human capital.

```r
# Generate treatment groups (time-invariant) with strong non-linearity
ps_true <- plogis(-1 -0.5*X1 + -0.5*X2)

treat <- rbinom(n, 1, ps_true)
```

In this case, _ps_true_ represents a logistic function that maps the relationship of X1 and X2 to the treatment variable _treat_. The assignment to treatment, therefore, is generated by a binomial distribution that observes these "probability scores" from this relationship and draw a success (participated in the training program) or a failure (refused to participate). Note that the relationship is negative: higher values of human capital, education or work experience, increase the likelihood of no participation.

Well, can we simply do an ATE calculation in this case? Let us finish constructing the data and calculate the classical ATE.


```r
# Treatment effect
tau <- 0.5

# Generate the data
df <- tibble(
  id = rep(1:n),
  X1 = X1,
  X2 = X2,
  treat  = treat,
  Y = tau*treat + 0.25*X1 + 0.25*X2 + rnorm(n, 0, 0.5)
)

# Naive ATE calculation
naive_ATE  <- df %>% 
  group_by(treat) %>% 
  summarize(meanY = mean(Y)) %>%
  summarize(ATE = diff(meanY)) %>% 
  pull()
```

```r
r$> naive_ATE
[1] 0.2863138
```

The true treatment effect of the training program is $tau = 0.5$. However, when calculating the ATE by simply finding average outcomes from treatment and control group, we are almost half far off the true value.

This can also be verified using an incomplete linear model:

```r
# Naive linear estimator
wrong_linear <- feols(Y ~ treat, data = df)[["coefficients"]][2]
```
```r
r$> wrong_linear
[1] 0.2863138
```

They are actually the same way of calculating a misspecified ATE. A good approach, therefore, is to calculate the propensity scores and find the ATE based on it. Let us assume we know the true relationship between the covariates and treatment assignment.

```r
# correct propensity scores
ps_model <- feglm(treat ~ X1 + X2, data = df, family = binomial)

# Plug the PS back in the data
df <- df %>% 
  mutate(
    ps = predict(ps_model, type = "response"),
    weight = ifelse(treat == 1, 1/ps, 1/(1 - ps))
  )

# Correct PS estimator
Y1 <- sum(df$Y[df$treat == 1] * df$weight[df$treat == 1]) / nrow(df)
Y0 <- sum(df$Y[df$treat == 0] * df$weight[df$treat == 0]) / nrow(df)

correct_PS <- Y1 - Y0
```
```r
r$> correct_PS
[1] 0.5085938
```

Wow! We actually got very close to the true estimate! Using the correct specification of the linear model also gives us a more correct estimate:

```r
r$> # Correct linear estmator
    correct_DiD <- feols(Y ~ treat + X1 + X2, data = df)
    summary(correct_DiD)
OLS estimation, Dep. Var.: Y
Observations: 10,000 
Standard-errors: IID 
            Estimate Std. Error   t value  Pr(>|t|)    
(Intercept) 0.000557   0.006062  0.091834   0.92683    
treat       0.511810   0.011573 44.224591 < 2.2e-16 ***
X1          0.249916   0.005092 49.077613 < 2.2e-16 ***
X2          0.247565   0.005191 47.687099 < 2.2e-16 ***
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
RMSE: 0.502913   Adj. R2: 0.341397
```

Not bad. The problem is that we most of the times don't know the true relationship between treatment assignment, outcome and covariates. 


